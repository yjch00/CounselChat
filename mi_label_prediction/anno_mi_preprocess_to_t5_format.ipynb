{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "716d6002",
   "metadata": {},
   "source": [
    "# AnnoMI 데이터셋을 T5 학습에 필요한 형태로 전처리하기\n",
    "- 가상환경 t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "291bb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../preprocessed_data/AnnoMI-full_v5.0.json', 'r') as f:\n",
    "    full = json.load(f)\n",
    "with open('../preprocessed_data/AnnoMI-full_v5.0_high.json', 'r') as f:\n",
    "    high = json.load(f)\n",
    "with open('../preprocessed_data/AnnoMI-full_v5.0_low.json', 'r') as f:\n",
    "    low = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3e64100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "110\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(full))\n",
    "print(len(high))\n",
    "print(len(low))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea8de3",
   "metadata": {},
   "source": [
    "## Window size에 따른 데이터 수 확인\n",
    "- 같은 speaker가 연속으로 나오는 경우도 잘 처리함 (ex. dialogue = high[10]['dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322d8cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# window_size: input으로 주는 dialogue history의 utterance 수\n",
    "def get_subsets(dialogue, window_size, last_speaker, allow_shorter_initial_subsets=False):\n",
    "    subsets = []\n",
    "    for i in range(len(dialogue)):\n",
    "        if dialogue[i]['speaker'] == last_speaker:\n",
    "            start = max(0, i - window_size)\n",
    "            subset = dialogue[start:i+1]\n",
    "            # Check if the subset ends with the desired speaker\n",
    "            if subset[-1]['speaker'] == last_speaker:\n",
    "                # Ensure the subset meets the window size requirement\n",
    "                if len(subset) == window_size + 1:\n",
    "                    subsets.append(subset)\n",
    "                # Handle shorter initial subsets based on the flag\n",
    "                elif allow_shorter_initial_subsets and start == 0:\n",
    "                    subsets.append(subset)\n",
    "    \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3af1898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting therapist's label (window size: 1): 4346\n",
      "predicting therapist's label (window size: 2): 4329\n",
      "predicting therapist's label (window size: 3): 4236\n",
      "predicting therapist's label (window size: 4): 4219\n",
      "predicting therapist's label (window size: 5): 4126\n",
      "predicting therapist's label (window size: 6): 4109\n",
      "predicting therapist's label (window size: 7): 4016\n",
      "predicting therapist's label (window size: 8): 3999\n",
      "predicting client's label (window size: 1): 4381\n",
      "predicting client's label (window size: 2): 4288\n",
      "predicting client's label (window size: 3): 4271\n",
      "predicting client's label (window size: 4): 4178\n",
      "predicting client's label (window size: 5): 4161\n",
      "predicting client's label (window size: 6): 4068\n",
      "predicting client's label (window size: 7): 4051\n",
      "predicting client's label (window size: 8): 3959\n"
     ]
    }
   ],
   "source": [
    "# Window size에 따른 데이터 수 계산\n",
    "window_min = 1\n",
    "window_max = 8\n",
    "\n",
    "for last_speaker in ['therapist', 'client']:\n",
    "    for window_size in range(window_min, window_max + 1):\n",
    "        count = 0\n",
    "        \n",
    "        for dialogue in high:\n",
    "            count += len(get_subsets(dialogue['dialogue'], window_size, last_speaker))\n",
    "            \n",
    "        print(f\"predicting {last_speaker}'s label (window size: {window_size}): {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646642f",
   "metadata": {},
   "source": [
    "## 데이터셋 전처리 & 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c63212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String의 첫 글자 대문자로\n",
    "def capitalize(s):\n",
    "    if not s:\n",
    "        return s  # Return the original string if it's empty\n",
    "    return s[0].upper() + s[1:]\n",
    "\n",
    "label_name_finegrained = {\n",
    "    \n",
    "    # Therapist\n",
    "    'reflection_simple': 'Simple Reflection',\n",
    "    'reflection_complex': 'Complex Reflection',\n",
    "    'question_open': 'Open Question',\n",
    "    'question_closed': 'Closed Question',\n",
    "    'input_advice': 'Advice',\n",
    "    'input_information': 'Information',\n",
    "    'input_negotiation': 'Negotiation',\n",
    "    'input_options': 'Options',\n",
    "    'other': 'Other',\n",
    "    \n",
    "    # # Client\n",
    "    # 'change': 'Change',\n",
    "    # 'neutral': 'Neutral',\n",
    "    # 'sustain': 'Sustain'\n",
    "    \n",
    "    # Client (Change & Not Change의 Binary Classification으로)\n",
    "    'change': 'Change',\n",
    "    'neutral': 'Not Change',\n",
    "    'sustain': 'Not Change'\n",
    "    \n",
    "}\n",
    "\n",
    "label_name_coarse = {\n",
    "    \n",
    "    'reflection_simple': 'Reflection',\n",
    "    'reflection_complex': 'Reflection',\n",
    "    'question_open': 'Question',\n",
    "    'question_closed': 'Question',\n",
    "    'input_advice': 'Input',\n",
    "    'input_information': 'Input',\n",
    "    'input_negotiation': 'Input',\n",
    "    'input_options': 'Input',\n",
    "    'other': 'Other',\n",
    "    \n",
    "    # # Client\n",
    "    # 'change': 'Change',\n",
    "    # 'neutral': 'Neutral',\n",
    "    # 'sustain': 'Sustain'\n",
    "    \n",
    "    # Client (Change & Not Change의 Binary Classification으로)\n",
    "    'change': 'Change',\n",
    "    'neutral': 'Not Change',\n",
    "    'sustain': 'Not Change'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23f056c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-True_finegrained_4347.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-True_coarse_4347.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-False_finegrained_4347.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-False_coarse_4347.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-True_finegrained_4330.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-True_coarse_4330.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-False_finegrained_4330.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-False_coarse_4330.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-True_finegrained_4237.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-True_coarse_4237.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-False_finegrained_4237.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-False_coarse_4237.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-True_finegrained_4220.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-True_coarse_4220.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-False_finegrained_4220.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-False_coarse_4220.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-True_finegrained_4127.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-True_coarse_4127.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-False_finegrained_4127.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-False_coarse_4127.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-True_finegrained_4110.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-True_coarse_4110.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-False_finegrained_4110.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-False_coarse_4110.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-True_finegrained_4017.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-True_coarse_4017.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-False_finegrained_4017.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-False_coarse_4017.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-True_finegrained_4000.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-True_coarse_4000.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-False_finegrained_4000.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-False_coarse_4000.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-1_inputlabel-True_finegrained_4382.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-1_inputlabel-True_coarse_4382.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-1_inputlabel-False_none_4382.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-2_inputlabel-True_finegrained_4289.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-2_inputlabel-True_coarse_4289.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-2_inputlabel-False_none_4289.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-3_inputlabel-True_finegrained_4272.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-3_inputlabel-True_coarse_4272.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-3_inputlabel-False_none_4272.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-4_inputlabel-True_finegrained_4179.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-4_inputlabel-True_coarse_4179.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-4_inputlabel-False_none_4179.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-5_inputlabel-True_finegrained_4162.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-5_inputlabel-True_coarse_4162.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-5_inputlabel-False_none_4162.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-6_inputlabel-True_finegrained_4069.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-6_inputlabel-True_coarse_4069.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-6_inputlabel-False_none_4069.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-7_inputlabel-True_finegrained_4052.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-7_inputlabel-True_coarse_4052.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-7_inputlabel-False_none_4052.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-8_inputlabel-True_finegrained_3960.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-8_inputlabel-True_coarse_3960.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-8_inputlabel-False_none_3960.csv\n",
      "CPU times: user 3.74 s, sys: 1.11 s, total: 4.85 s\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # AnnoMI-full_v3.1 & finegrained/coarse 사용했을 때\n",
    "# import pandas as pd\n",
    "\n",
    "# window_min = 1\n",
    "# window_max = 8\n",
    "\n",
    "# filename_list = []\n",
    "\n",
    "# for last_speaker in ['therapist', 'client']: # last_speaker: predict할 speaker\n",
    "#     for window_size in range(window_min, window_max + 1):\n",
    "#         for include_label in [True, False]:\n",
    "#             for granularity in ['finegrained', 'coarse']:\n",
    "#                 if granularity == 'finegrained':\n",
    "#                     label_name = label_name_finegrained\n",
    "#                 elif granularity == 'coarse':\n",
    "#                     label_name = label_name_coarse\n",
    "            \n",
    "#                 source = []\n",
    "#                 target = []\n",
    "            \n",
    "#                 for dialogue in high: # high 데이터만 사용        \n",
    "#                     subsets = get_subsets(dialogue['dialogue'], window_size, last_speaker)\n",
    "#                     for subset in subsets: \n",
    "                        \n",
    "#                         # Source Text (Input)\n",
    "#                         source_text = f\"Predict next {last_speaker}'s dialogue act: \"\n",
    "\n",
    "#                         for utterance in subset[:-1]: # 마지막 utterance는 label로 사용\n",
    "#                             # Label\n",
    "#                             if include_label:\n",
    "#                                 source_text += f\"[{capitalize(utterance['speaker'])}: \"\n",
    "#                                 for label in utterance[f\"{utterance['speaker']}_label\"]:\n",
    "#                                     source_text += label_name[label]\n",
    "#                                     source_text += \", \"\n",
    "#                                 source_text = source_text[:-2]\n",
    "#                                 source_text += '] '\n",
    "#                             else:\n",
    "#                                 source_text += f\"[{capitalize(utterance['speaker'])}] \"\n",
    "\n",
    "#                             # Utterance\n",
    "#                             source_text += utterance['utterance']\n",
    "#                             source_text += ' '\n",
    "                        \n",
    "#                         source.append(source_text.strip())\n",
    "\n",
    "#                         # Target Text (Output)\n",
    "#                         target_text = f\"[{capitalize(subset[-1]['speaker'])}: \"\n",
    "#                         for label in subset[-1][f\"{subset[-1]['speaker']}_label\"]:\n",
    "#                             target_text += label_name[label]\n",
    "#                             target_text += \", \"\n",
    "#                         target_text = target_text[:-2]\n",
    "#                         target_text += ']'\n",
    "                        \n",
    "#                         target.append(target_text)\n",
    "                        \n",
    "#                 df = pd.DataFrame({'source_text': source, 'target_text': target})\n",
    "                \n",
    "#                 # pred-client, inputlabel-False이면 coarse/finegrained 의미 없음 \n",
    "#                 # (therapist label이 한 번도 등장 안 해서 똑같은 데이터임)\n",
    "#                 if last_speaker == 'client' and include_label == False:\n",
    "#                     filename = f'AnnoMI_dataset-high_pred-{last_speaker}_window-{window_size}_inputlabel-{include_label}_none_{len(df)}.csv'\n",
    "#                 else:\n",
    "#                     filename = f'AnnoMI_dataset-high_pred-{last_speaker}_window-{window_size}_inputlabel-{include_label}_{granularity}_{len(df)}.csv'\n",
    "\n",
    "#                 if filename not in filename_list:\n",
    "#                     filename_list.append(filename)\n",
    "#                     df.to_csv(f't5_dataset/{filename}', index=False)\n",
    "#                     print(f'Saved {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e58592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-True_integrated_4346.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-False_integrated_4346.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-True_integrated_4329.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-False_integrated_4329.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-True_integrated_4236.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-False_integrated_4236.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-True_integrated_4219.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-False_integrated_4219.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-True_integrated_4126.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-False_integrated_4126.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-True_integrated_4109.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-False_integrated_4109.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-True_integrated_4016.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-False_integrated_4016.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-True_integrated_3999.csv\n",
      "Saved AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-False_integrated_3999.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-1_inputlabel-True_integrated_4381.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-1_inputlabel-False_none_4381.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-2_inputlabel-True_integrated_4288.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-2_inputlabel-False_none_4288.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-3_inputlabel-True_integrated_4271.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-3_inputlabel-False_none_4271.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-4_inputlabel-True_integrated_4178.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-4_inputlabel-False_none_4178.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-5_inputlabel-True_integrated_4161.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-5_inputlabel-False_none_4161.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-6_inputlabel-True_integrated_4068.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-6_inputlabel-False_none_4068.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-7_inputlabel-True_integrated_4051.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-7_inputlabel-False_none_4051.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-8_inputlabel-True_integrated_3959.csv\n",
      "Saved AnnoMI_dataset-high_pred-client_window-8_inputlabel-False_none_3959.csv\n",
      "CPU times: user 1.53 s, sys: 188 ms, total: 1.71 s\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# AnnoMI-full_v5.0 & integrated 사용했을 때\n",
    "import pandas as pd\n",
    "\n",
    "window_min = 1\n",
    "window_max = 8\n",
    "\n",
    "filename_list = []\n",
    "\n",
    "for last_speaker in ['therapist', 'client']: # last_speaker: predict할 speaker\n",
    "    for window_size in range(window_min, window_max + 1):\n",
    "        for include_label in [True, False]:\n",
    "            for granularity in ['integrated']:\n",
    "            \n",
    "                source = []\n",
    "                target = []\n",
    "            \n",
    "                for dialogue in high: # high 데이터만 사용        \n",
    "                    subsets = get_subsets(dialogue['dialogue'], window_size, last_speaker)\n",
    "                    for subset in subsets: \n",
    "                        \n",
    "                        # Source Text (Input)\n",
    "                        source_text = f\"Predict next {last_speaker}'s dialogue act: \"\n",
    "\n",
    "                        for utterance in subset[:-1]: # 마지막 utterance는 label로 사용\n",
    "                            # Label\n",
    "                            if include_label:\n",
    "                                source_text += f\"[{capitalize(utterance['speaker'])}: \"\n",
    "                                source_text += f\"{utterance['label']}] \"\n",
    "                                \n",
    "                            else:\n",
    "                                source_text += f\"[{capitalize(utterance['speaker'])}] \"\n",
    "\n",
    "                            # Utterance\n",
    "                            source_text += utterance['utterance']\n",
    "                            source_text += ' '\n",
    "                        \n",
    "                        source.append(source_text.strip())\n",
    "\n",
    "                        # Target Text (Output)\n",
    "                        target_text = f\"[{capitalize(subset[-1]['speaker'])}: \"\n",
    "                        target_text += f\"{subset[-1]['label']}]\"\n",
    "\n",
    "                        target.append(target_text)\n",
    "                        \n",
    "                df = pd.DataFrame({'source_text': source, 'target_text': target})\n",
    "                \n",
    "                # pred-client, inputlabel-False이면 coarse/finegrained 의미 없음 \n",
    "                # (therapist label이 한 번도 등장 안 해서 똑같은 데이터임)\n",
    "                if last_speaker == 'client' and include_label == False:\n",
    "                    filename = f'AnnoMI_dataset-high_pred-{last_speaker}_window-{window_size}_inputlabel-{include_label}_none_{len(df)}.csv'\n",
    "                else:\n",
    "                    filename = f'AnnoMI_dataset-high_pred-{last_speaker}_window-{window_size}_inputlabel-{include_label}_{granularity}_{len(df)}.csv'\n",
    "\n",
    "                if filename not in filename_list:\n",
    "                    filename_list.append(filename)\n",
    "                    df.to_csv(f't5_dataset/{filename}', index=False)\n",
    "                    print(f'Saved {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e72bdf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14001aae",
   "metadata": {},
   "source": [
    "## Window size에 따른 sequence length 확인\n",
    "- Window size 8까지 가도 sequence length 512 넘어가는 거 생각보다 별로 없음 (별로 영향 안 미칠듯)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70108dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_list = ['AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-True_finegrained_4347.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-True_coarse_4347.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-False_finegrained_4347.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-False_coarse_4347.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-True_finegrained_4330.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-True_coarse_4330.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-False_finegrained_4330.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-False_coarse_4330.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-True_finegrained_4237.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-True_coarse_4237.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-False_finegrained_4237.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-False_coarse_4237.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-True_finegrained_4220.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-True_coarse_4220.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-False_finegrained_4220.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-False_coarse_4220.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-True_finegrained_4127.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-True_coarse_4127.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-False_finegrained_4127.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-False_coarse_4127.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-True_finegrained_4110.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-True_coarse_4110.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-False_finegrained_4110.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-False_coarse_4110.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-True_finegrained_4017.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-True_coarse_4017.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-False_finegrained_4017.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-False_coarse_4017.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-True_finegrained_4000.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-True_coarse_4000.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-False_finegrained_4000.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-False_coarse_4000.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-1_inputlabel-True_finegrained_4382.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-1_inputlabel-True_coarse_4382.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-1_inputlabel-False_none_4382.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-2_inputlabel-True_finegrained_4289.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-2_inputlabel-True_coarse_4289.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-2_inputlabel-False_none_4289.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-3_inputlabel-True_finegrained_4272.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-3_inputlabel-True_coarse_4272.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-3_inputlabel-False_none_4272.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-4_inputlabel-True_finegrained_4179.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-4_inputlabel-True_coarse_4179.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-4_inputlabel-False_none_4179.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-5_inputlabel-True_finegrained_4162.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-5_inputlabel-True_coarse_4162.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-5_inputlabel-False_none_4162.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-6_inputlabel-True_finegrained_4069.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-6_inputlabel-True_coarse_4069.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-6_inputlabel-False_none_4069.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-7_inputlabel-True_finegrained_4052.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-7_inputlabel-True_coarse_4052.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-7_inputlabel-False_none_4052.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-8_inputlabel-True_finegrained_3960.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-8_inputlabel-True_coarse_3960.csv',\n",
    "#                  'AnnoMI_dataset-high_pred-client_window-8_inputlabel-False_none_3960.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4535bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = ['AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-True_integrated_4346.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-False_integrated_4346.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-True_integrated_4329.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-False_integrated_4329.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-True_integrated_4236.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-False_integrated_4236.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-True_integrated_4219.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-False_integrated_4219.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-True_integrated_4126.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-False_integrated_4126.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-True_integrated_4109.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-False_integrated_4109.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-True_integrated_4016.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-False_integrated_4016.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-True_integrated_3999.csv',\n",
    "                 'AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-False_integrated_3999.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-1_inputlabel-True_integrated_4381.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-1_inputlabel-False_none_4381.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-2_inputlabel-True_integrated_4288.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-2_inputlabel-False_none_4288.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-3_inputlabel-True_integrated_4271.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-3_inputlabel-False_none_4271.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-4_inputlabel-True_integrated_4178.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-4_inputlabel-False_none_4178.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-5_inputlabel-True_integrated_4161.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-5_inputlabel-False_none_4161.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-6_inputlabel-True_integrated_4068.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-6_inputlabel-False_none_4068.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-7_inputlabel-True_integrated_4051.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-7_inputlabel-False_none_4051.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-8_inputlabel-True_integrated_3959.csv',\n",
    "                 'AnnoMI_dataset-high_pred-client_window-8_inputlabel-False_none_3959.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ae1801f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-True_integrated_4346.csv **\n",
      "[Source Text] Mean: 41.75 | Std Dev: 29.04 | Over 512: 0 out of 4346\n",
      "[Target Text] Mean: 8.75 | Std Dev: 0.44 | Over 512: 0 out of 4346\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-1_inputlabel-False_integrated_4346.csv **\n",
      "[Source Text] Mean: 39.0 | Std Dev: 29.12 | Over 512: 0 out of 4346\n",
      "[Target Text] Mean: 8.75 | Std Dev: 0.44 | Over 512: 0 out of 4346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-True_integrated_4329.csv **\n",
      "[Source Text] Mean: 73.25 | Std Dev: 40.58 | Over 512: 1 out of 4329\n",
      "[Target Text] Mean: 8.75 | Std Dev: 0.44 | Over 512: 0 out of 4329\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-2_inputlabel-False_integrated_4329.csv **\n",
      "[Source Text] Mean: 67.04 | Std Dev: 40.52 | Over 512: 1 out of 4329\n",
      "[Target Text] Mean: 8.75 | Std Dev: 0.44 | Over 512: 0 out of 4329\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-True_integrated_4236.csv **\n",
      "[Source Text] Mean: 103.89 | Std Dev: 52.1 | Over 512: 1 out of 4236\n",
      "[Target Text] Mean: 8.75 | Std Dev: 0.44 | Over 512: 0 out of 4236\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-3_inputlabel-False_integrated_4236.csv **\n",
      "[Source Text] Mean: 94.93 | Std Dev: 52.07 | Over 512: 1 out of 4236\n",
      "[Target Text] Mean: 8.75 | Std Dev: 0.44 | Over 512: 0 out of 4236\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-True_integrated_4219.csv **\n",
      "[Source Text] Mean: 135.0 | Std Dev: 60.93 | Over 512: 2 out of 4219\n",
      "[Target Text] Mean: 8.75 | Std Dev: 0.44 | Over 512: 0 out of 4219\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-4_inputlabel-False_integrated_4219.csv **\n",
      "[Source Text] Mean: 122.59 | Std Dev: 60.76 | Over 512: 2 out of 4219\n",
      "[Target Text] Mean: 8.75 | Std Dev: 0.44 | Over 512: 0 out of 4219\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-True_integrated_4126.csv **\n",
      "[Source Text] Mean: 165.71 | Std Dev: 70.73 | Over 512: 14 out of 4126\n",
      "[Target Text] Mean: 8.74 | Std Dev: 0.45 | Over 512: 0 out of 4126\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-5_inputlabel-False_integrated_4126.csv **\n",
      "[Source Text] Mean: 150.55 | Std Dev: 70.58 | Over 512: 11 out of 4126\n",
      "[Target Text] Mean: 8.74 | Std Dev: 0.45 | Over 512: 0 out of 4126\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-True_integrated_4109.csv **\n",
      "[Source Text] Mean: 196.55 | Std Dev: 78.7 | Over 512: 21 out of 4109\n",
      "[Target Text] Mean: 8.74 | Std Dev: 0.45 | Over 512: 0 out of 4109\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-6_inputlabel-False_integrated_4109.csv **\n",
      "[Source Text] Mean: 177.96 | Std Dev: 78.43 | Over 512: 17 out of 4109\n",
      "[Target Text] Mean: 8.74 | Std Dev: 0.45 | Over 512: 0 out of 4109\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-True_integrated_4016.csv **\n",
      "[Source Text] Mean: 226.85 | Std Dev: 86.99 | Over 512: 47 out of 4016\n",
      "[Target Text] Mean: 8.74 | Std Dev: 0.45 | Over 512: 0 out of 4016\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-7_inputlabel-False_integrated_4016.csv **\n",
      "[Source Text] Mean: 205.49 | Std Dev: 86.68 | Over 512: 40 out of 4016\n",
      "[Target Text] Mean: 8.74 | Std Dev: 0.45 | Over 512: 0 out of 4016\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-True_integrated_3999.csv **\n",
      "[Source Text] Mean: 257.42 | Std Dev: 94.17 | Over 512: 86 out of 3999\n",
      "[Target Text] Mean: 8.74 | Std Dev: 0.45 | Over 512: 0 out of 3999\n",
      "\n",
      "** AnnoMI_dataset-high_pred-therapist_window-8_inputlabel-False_integrated_3999.csv **\n",
      "[Source Text] Mean: 232.63 | Std Dev: 93.74 | Over 512: 60 out of 3999\n",
      "[Target Text] Mean: 8.74 | Std Dev: 0.45 | Over 512: 0 out of 3999\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-1_inputlabel-True_integrated_4381.csv **\n",
      "[Source Text] Mean: 41.43 | Std Dev: 26.95 | Over 512: 0 out of 4381\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.18 | Over 512: 0 out of 4381\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-1_inputlabel-False_none_4381.csv **\n",
      "[Source Text] Mean: 37.98 | Std Dev: 26.63 | Over 512: 0 out of 4381\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.18 | Over 512: 0 out of 4381\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-2_inputlabel-True_integrated_4288.csv **\n",
      "[Source Text] Mean: 72.16 | Std Dev: 39.78 | Over 512: 0 out of 4288\n",
      "[Target Text] Mean: 9.46 | Std Dev: 1.19 | Over 512: 0 out of 4288\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-2_inputlabel-False_none_4288.csv **\n",
      "[Source Text] Mean: 65.95 | Std Dev: 39.58 | Over 512: 0 out of 4288\n",
      "[Target Text] Mean: 9.46 | Std Dev: 1.19 | Over 512: 0 out of 4288\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-3_inputlabel-True_integrated_4271.csv **\n",
      "[Source Text] Mean: 103.52 | Std Dev: 50.69 | Over 512: 1 out of 4271\n",
      "[Target Text] Mean: 9.46 | Std Dev: 1.19 | Over 512: 0 out of 4271\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-3_inputlabel-False_none_4271.csv **\n",
      "[Source Text] Mean: 93.86 | Std Dev: 50.39 | Over 512: 1 out of 4271\n",
      "[Target Text] Mean: 9.46 | Std Dev: 1.19 | Over 512: 0 out of 4271\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-4_inputlabel-True_integrated_4178.csv **\n",
      "[Source Text] Mean: 134.16 | Std Dev: 60.85 | Over 512: 2 out of 4178\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.19 | Over 512: 0 out of 4178\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-4_inputlabel-False_none_4178.csv **\n",
      "[Source Text] Mean: 121.75 | Std Dev: 60.58 | Over 512: 2 out of 4178\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.19 | Over 512: 0 out of 4178\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-5_inputlabel-True_integrated_4161.csv **\n",
      "[Source Text] Mean: 165.16 | Std Dev: 69.74 | Over 512: 6 out of 4161\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.19 | Over 512: 0 out of 4161\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-5_inputlabel-False_none_4161.csv **\n",
      "[Source Text] Mean: 149.3 | Std Dev: 69.37 | Over 512: 5 out of 4161\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.19 | Over 512: 0 out of 4161\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-6_inputlabel-True_integrated_4068.csv **\n",
      "[Source Text] Mean: 195.73 | Std Dev: 78.71 | Over 512: 23 out of 4068\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.19 | Over 512: 0 out of 4068\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-6_inputlabel-False_none_4068.csv **\n",
      "[Source Text] Mean: 177.12 | Std Dev: 78.32 | Over 512: 19 out of 4068\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.19 | Over 512: 0 out of 4068\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-7_inputlabel-True_integrated_4051.csv **\n",
      "[Source Text] Mean: 226.54 | Std Dev: 86.66 | Over 512: 42 out of 4051\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.19 | Over 512: 0 out of 4051\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-7_inputlabel-False_none_4051.csv **\n",
      "[Source Text] Mean: 204.5 | Std Dev: 86.16 | Over 512: 34 out of 4051\n",
      "[Target Text] Mean: 9.45 | Std Dev: 1.19 | Over 512: 0 out of 4051\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-8_inputlabel-True_integrated_3959.csv **\n",
      "[Source Text] Mean: 256.88 | Std Dev: 94.47 | Over 512: 83 out of 3959\n",
      "[Target Text] Mean: 9.44 | Std Dev: 1.19 | Over 512: 0 out of 3959\n",
      "\n",
      "** AnnoMI_dataset-high_pred-client_window-8_inputlabel-False_none_3959.csv **\n",
      "[Source Text] Mean: 232.08 | Std Dev: 93.95 | Over 512: 66 out of 3959\n",
      "[Target Text] Mean: 9.44 | Std Dev: 1.19 | Over 512: 0 out of 3959\n",
      "\n",
      "CPU times: user 1min 9s, sys: 268 ms, total: 1min 9s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "def count_length(tokenizer, text):\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    sequence_length = tokens['input_ids'].size(1)\n",
    "    \n",
    "    return sequence_length\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "for filename in filename_list:\n",
    "    df = pd.read_csv(f't5_dataset/{filename}')\n",
    "\n",
    "    source_length = [count_length(tokenizer, text) for text in list(df['source_text'])]\n",
    "    target_length = [count_length(tokenizer, text) for text in list(df['target_text'])]\n",
    "\n",
    "    source_mean = np.mean(source_length)\n",
    "    source_std_dev = np.std(source_length)\n",
    "    source_over_512 = len([i for i in source_length if i > 512])\n",
    "\n",
    "    target_mean = np.mean(target_length)\n",
    "    target_std_dev = np.std(target_length)\n",
    "    target_over_512 = len([i for i in target_length if i > 512])\n",
    "\n",
    "    print(f\"** {filename} **\")\n",
    "    print(f'[Source Text] Mean: {round(source_mean, 2)} | Std Dev: {round(source_std_dev, 2)} | Over 512: {source_over_512} out of {len(df)}')\n",
    "    print(f'[Target Text] Mean: {round(target_mean, 2)} | Std Dev: {round(target_std_dev, 2)} | Over 512: {target_over_512} out of {len(df)}')\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:t5]",
   "language": "python",
   "name": "conda-env-t5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
